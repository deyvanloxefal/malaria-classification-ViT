{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tahap 1: Impor Library dan Pengaturan Awal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T08:49:39.346576Z",
     "iopub.status.busy": "2025-06-22T08:49:39.346303Z",
     "iopub.status.idle": "2025-06-22T08:50:09.161426Z",
     "shell.execute_reply": "2025-06-22T08:50:09.160872Z",
     "shell.execute_reply.started": "2025-06-22T08:49:39.346558Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyswarms\n",
      "  Downloading pyswarms-1.3.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.15.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pyswarms) (3.7.2)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from pyswarms) (25.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pyswarms) (4.67.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyswarms) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pyswarms) (6.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (11.1.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pyswarms) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pyswarms) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pyswarms) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pyswarms) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pyswarms) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pyswarms) (2.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pyswarms) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pyswarms) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pyswarms) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pyswarms) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pyswarms) (2024.2.0)\n",
      "Downloading pyswarms-1.3.0-py2.py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyswarms\n",
      "Successfully installed pyswarms-1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 08:49:54.614883: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750582194.811755      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750582194.867878      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyswarms\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Library untuk PSO dan visualisasinya\n",
    "import pyswarms as ps\n",
    "from pyswarms.utils import plotters as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T08:51:23.837619Z",
     "iopub.status.busy": "2025-06-22T08:51:23.836965Z",
     "iopub.status.idle": "2025-06-22T08:51:23.843514Z",
     "shell.execute_reply": "2025-06-22T08:51:23.842893Z",
     "shell.execute_reply.started": "2025-06-22T08:51:23.837594Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed diset ke 42 untuk hasil yang konsisten.\n"
     ]
    }
   ],
   "source": [
    "# --- SEED UNTUK REPRODUCIBILITY ---\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Pengaturan ini membuat proses lebih lambat tapi hasilnya konsisten\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"Random seed diset ke {SEED} untuk hasil yang konsisten.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tahap 2: Konfigurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T08:51:29.392223Z",
     "iopub.status.busy": "2025-06-22T08:51:29.391744Z",
     "iopub.status.idle": "2025-06-22T08:51:29.398042Z",
     "shell.execute_reply": "2025-06-22T08:51:29.397276Z",
     "shell.execute_reply.started": "2025-06-22T08:51:29.392196Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Konfigurasi Ditetapkan ---\n",
      "Device: cuda\n",
      "Model: google/vit-base-patch16-224\n",
      "PSO: 5 partikel, 5 iterasi, 3 epoch per trial\n",
      "Opsi PSO (Klasik): c1=2.0, c2=2.0, w=0.7\n"
     ]
    }
   ],
   "source": [
    "# --- Konfigurasi Model & Data ---\n",
    "MODEL_NAME = \"google/vit-base-patch16-224\"\n",
    "NUM_CLASSES = 2\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- PATH DATASET (SESUAIKAN JIKA PERLU) ---\n",
    "BASE_DATA_DIR = \"/kaggle/input/cell-images-for-detecting-malaria/cell_images/cell_images/\"\n",
    "\n",
    "# --- Konfigurasi Pencarian PSO ---\n",
    "# Menggunakan nilai yang lebih ringan dan praktis\n",
    "N_PARTICLES = 5       # Jumlah partikel\n",
    "N_ITERATIONS = 5      # Jumlah iterasi\n",
    "EPOCHS_PER_TRIAL = 3  # Epoch singkat untuk setiap evaluasi\n",
    "\n",
    "# Opsi PSO menggunakan Konfigurasi Klasik yang disederhanakan\n",
    "PSO_OPTIONS = {\n",
    "    'c1': 2.0,\n",
    "    'c2': 2.0,\n",
    "    'w': 0.7  # Nilai statis sebagai kompromi dari inersia menurun\n",
    "}\n",
    "\n",
    "# Batasan ruang pencarian\n",
    "MIN_BOUNDS = [1e-6, 16]  # [min_lr, min_batch_size]\n",
    "MAX_BOUNDS = [1e-3, 64]  # [max_lr, max_batch_size]\n",
    "BOUNDS = (np.array(MIN_BOUNDS), np.array(MAX_BOUNDS))\n",
    "\n",
    "print(\"\\n--- Konfigurasi Ditetapkan ---\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"PSO: {N_PARTICLES} partikel, {N_ITERATIONS} iterasi, {EPOCHS_PER_TRIAL} epoch per trial\")\n",
    "print(f\"Opsi PSO (Klasik): c1={PSO_OPTIONS['c1']}, c2={PSO_OPTIONS['c2']}, w={PSO_OPTIONS['w']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tahap 3: Persiapan Data dan Fungsi Bantu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T08:51:50.875004Z",
     "iopub.status.busy": "2025-06-22T08:51:50.874701Z",
     "iopub.status.idle": "2025-06-22T08:51:53.044266Z",
     "shell.execute_reply": "2025-06-22T08:51:53.043436Z",
     "shell.execute_reply.started": "2025-06-22T08:51:50.874983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memuat dan membagi data...\n",
      "Data siap: 13779 gambar digunakan (Train: 11023, Val: 2756)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3414c7a4674e24adb143cf960f53c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MalariaDataset(Dataset):\n",
    "    \"\"\"Kelas Dataset Kustom untuk data malaria.\"\"\"\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def snap_to_valid_batch_size(n, values=[16, 32, 64]):\n",
    "    \"\"\"Memaksa nilai batch size ke pilihan valid terdekat (pangkat 2).\"\"\"\n",
    "    return min(values, key=lambda x: abs(x - n))\n",
    "\n",
    "# --- Memuat dan Membagi Data (Dilakukan Sekali) ---\n",
    "print(\"\\nMemuat dan membagi data...\")\n",
    "parasitized_dir = os.path.join(BASE_DATA_DIR, \"Parasitized\")\n",
    "uninfected_dir = os.path.join(BASE_DATA_DIR, \"Uninfected\")\n",
    "\n",
    "parasitized_files = [os.path.join(parasitized_dir, f) for f in os.listdir(parasitized_dir) if f.endswith('.png')]\n",
    "uninfected_files = [os.path.join(uninfected_dir, f) for f in os.listdir(uninfected_dir) if f.endswith('.png')]\n",
    "\n",
    "all_files = parasitized_files + uninfected_files\n",
    "all_labels = [0] * len(parasitized_files) + [1] * len(uninfected_files)\n",
    "\n",
    "# Menggunakan subset 50% data untuk tuning agar proses lebih cepat\n",
    "_, subset_files, _, subset_labels = train_test_split(\n",
    "    all_files, all_labels, test_size=0.5, stratify=all_labels, random_state=SEED\n",
    ")\n",
    "\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    subset_files, subset_labels, test_size=0.2, stratify=subset_labels, random_state=SEED\n",
    ")\n",
    "print(f\"Data siap: {len(subset_files)} gambar digunakan (Train: {len(train_files)}, Val: {len(val_files)})\")\n",
    "\n",
    "# --- Fungsi Persiapan DataLoader & Transformasi ---\n",
    "image_processor = ViTImageProcessor.from_pretrained(MODEL_NAME)\n",
    "target_size = (image_processor.size['height'], image_processor.size['width'])\n",
    "\n",
    "def prepare_dataloaders(batch_size):\n",
    "    \"\"\"Mempersiapkan DataLoader berdasarkan batch size yang diberikan.\"\"\"\n",
    "    def vit_core_processor_transform(pil_image, processor):\n",
    "        return processor(images=pil_image, return_tensors='pt')['pixel_values'].squeeze(0)\n",
    "\n",
    "    train_transforms = T.Compose([\n",
    "        T.RandomResizedCrop(target_size, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "        T.RandomRotation(degrees=20), # Tingkatkan sedikit rotasi\n",
    "        T.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.12), # Tingkatkan sedikit jitter\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomVerticalFlip(), # Tambahkan vertical flip, bisa relevan untuk sel\n",
    "        lambda img: vit_core_processor_transform(img, image_processor)\n",
    "    ])\n",
    "    val_transforms = T.Compose([\n",
    "        lambda img: vit_core_processor_transform(img, image_processor)\n",
    "    ])\n",
    "\n",
    "    train_dataset = MalariaDataset(train_files, train_labels, transform=train_transforms)\n",
    "    val_dataset = MalariaDataset(val_files, val_labels, transform=val_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tahap 4: Fungsi Objektif PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T08:52:04.702483Z",
     "iopub.status.busy": "2025-06-22T08:52:04.701746Z",
     "iopub.status.idle": "2025-06-22T08:52:04.714706Z",
     "shell.execute_reply": "2025-06-22T08:52:04.713953Z",
     "shell.execute_reply.started": "2025-06-22T08:52:04.702451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def objective_function(particles):\n",
    "    \"\"\"Mengevaluasi setiap partikel dan mengembalikan cost-nya.\"\"\"\n",
    "    num_particles = particles.shape[0]\n",
    "    costs = []\n",
    "\n",
    "    for i, p in enumerate(particles):\n",
    "        learning_rate = p[0]\n",
    "        # Menggunakan fungsi bantu untuk batch size\n",
    "        batch_size = snap_to_valid_batch_size(p[1])\n",
    "\n",
    "        print(f\"\\n[Trial Partikel {i+1}/{num_particles}] LR: {learning_rate:.1E}, BS: {batch_size}\")\n",
    "\n",
    "        try:\n",
    "            model = ViTForImageClassification.from_pretrained(\n",
    "                MODEL_NAME, num_labels=NUM_CLASSES, ignore_mismatched_sizes=True\n",
    "            ).to(DEVICE)\n",
    "\n",
    "            train_loader, val_loader = prepare_dataloaders(batch_size)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            best_val_accuracy_in_trial = 0.0\n",
    "\n",
    "            for epoch in range(EPOCHS_PER_TRIAL):\n",
    "                model.train()\n",
    "                for inputs, labels in train_loader:\n",
    "                    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(pixel_values=inputs).logits\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                val_preds_all, val_labels_all = [], []\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in val_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(pixel_values=inputs).logits\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        val_preds_all.extend(preds.cpu().numpy())\n",
    "                        val_labels_all.extend(labels.cpu().numpy())\n",
    "\n",
    "                epoch_val_accuracy = accuracy_score(val_labels_all, val_preds_all)\n",
    "                if epoch_val_accuracy > best_val_accuracy_in_trial:\n",
    "                    best_val_accuracy_in_trial = epoch_val_accuracy\n",
    "\n",
    "            cost = 1.0 - best_val_accuracy_in_trial\n",
    "            print(f\"  > Selesai. Best Val Acc: {best_val_accuracy_in_trial:.4f} -> Cost: {cost:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  > ERROR: {e}. Memberikan penalti.\")\n",
    "            cost = 1.0\n",
    "\n",
    "        costs.append(cost)\n",
    "    return np.array(costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tahap 5: Eksekusi dan Visualisasi PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T08:52:08.307783Z",
     "iopub.status.busy": "2025-06-22T08:52:08.307511Z",
     "iopub.status.idle": "2025-06-22T13:29:16.636870Z",
     "shell.execute_reply": "2025-06-22T13:29:16.635406Z",
     "shell.execute_reply.started": "2025-06-22T08:52:08.307764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 08:52:08,320 - pyswarms.single.global_best - INFO - Optimize for 5 iters with {'c1': 2.0, 'c2': 2.0, 'w': 0.7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "--- MEMULAI OPTIMASI HYPERPARAMETER DENGAN PSO ---\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best:   0%|          |0/5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial Partikel 1/5] LR: 6.1E-04, BS: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c325e77f483459c9234d23540cbacbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568e12d329f5478cae3fc025700103bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9561 -> Cost: 0.0439\n",
      "\n",
      "[Trial Partikel 2/5] LR: 2.9E-04, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9590 -> Cost: 0.0410\n",
      "\n",
      "[Trial Partikel 3/5] LR: 4.6E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9601 -> Cost: 0.0399\n",
      "\n",
      "[Trial Partikel 4/5] LR: 2.0E-04, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9648 -> Cost: 0.0352\n",
      "\n",
      "[Trial Partikel 5/5] LR: 5.9E-04, BS: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "pyswarms.single.global_best:  20%|██        |1/5, best_cost=0.0352"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9550 -> Cost: 0.0450\n",
      "\n",
      "[Trial Partikel 1/5] LR: 5.2E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9597 -> Cost: 0.0403\n",
      "\n",
      "[Trial Partikel 2/5] LR: 7.0E-04, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9546 -> Cost: 0.0454\n",
      "\n",
      "[Trial Partikel 3/5] LR: 7.7E-04, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9499 -> Cost: 0.0501\n",
      "\n",
      "[Trial Partikel 4/5] LR: 6.4E-04, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9579 -> Cost: 0.0421\n",
      "\n",
      "[Trial Partikel 5/5] LR: 1.0E-03, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "pyswarms.single.global_best:  40%|████      |2/5, best_cost=0.0352"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9550 -> Cost: 0.0450\n",
      "\n",
      "[Trial Partikel 1/5] LR: 4.6E-04, BS: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9546 -> Cost: 0.0454\n",
      "\n",
      "[Trial Partikel 2/5] LR: 8.0E-04, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9528 -> Cost: 0.0472\n",
      "\n",
      "[Trial Partikel 3/5] LR: 2.1E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9670 -> Cost: 0.0330\n",
      "\n",
      "[Trial Partikel 4/5] LR: 2.5E-04, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9634 -> Cost: 0.0366\n",
      "\n",
      "[Trial Partikel 5/5] LR: 9.5E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "pyswarms.single.global_best:  60%|██████    |3/5, best_cost=0.033 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9568 -> Cost: 0.0432\n",
      "\n",
      "[Trial Partikel 1/5] LR: 3.6E-04, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9594 -> Cost: 0.0406\n",
      "\n",
      "[Trial Partikel 2/5] LR: 3.3E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9648 -> Cost: 0.0352\n",
      "\n",
      "[Trial Partikel 3/5] LR: 9.1E-04, BS: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9492 -> Cost: 0.0508\n",
      "\n",
      "[Trial Partikel 4/5] LR: 1.6E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9695 -> Cost: 0.0305\n",
      "\n",
      "[Trial Partikel 5/5] LR: 3.8E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "pyswarms.single.global_best:  80%|████████  |4/5, best_cost=0.0305"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9612 -> Cost: 0.0388\n",
      "\n",
      "[Trial Partikel 1/5] LR: 7.9E-04, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9583 -> Cost: 0.0417\n",
      "\n",
      "[Trial Partikel 2/5] LR: 3.9E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9554 -> Cost: 0.0446\n",
      "\n",
      "[Trial Partikel 3/5] LR: 1.7E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9663 -> Cost: 0.0337\n",
      "\n",
      "[Trial Partikel 4/5] LR: 9.0E-04, BS: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9499 -> Cost: 0.0501\n",
      "\n",
      "[Trial Partikel 5/5] LR: 9.2E-05, BS: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "pyswarms.single.global_best: 100%|██████████|5/5, best_cost=0.0287\n",
      "2025-06-22 13:29:16,559 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.028664731494920215, best pos: [9.19422509e-05 4.27585879e+01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  > Selesai. Best Val Acc: 0.9713 -> Cost: 0.0287\n",
      "\n",
      "\n",
      "==================================================\n",
      "--- OPTIMASI PSO SELESAI ---\n",
      "==================================================\n",
      "\n",
      "--- Ringkasan Hasil per Iterasi ---\n",
      " iterasi  best_cost_iterasi_ini  best_lr_saat_ini  best_bs_saat_ini\n",
      "       1               0.035196          0.000593                16\n",
      "       2               0.035196          0.000999                32\n",
      "       3               0.033019          0.000950                64\n",
      "       4               0.030479          0.000379                64\n",
      "       5               0.028665          0.000092                32\n",
      "\n",
      "Akurasi validasi tertinggi yang dicapai: 0.9713\n",
      "\n",
      ">>> HYPERPARAMETER TERBAIK YANG DITEMUKAN <<<\n",
      "--------------------------------------------------\n",
      "  Learning Rate: 0.000092\n",
      "  Batch Size: 32\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Visualisasi Proses Optimasi ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pyswarms.utils.plotters' has no attribute 'plot_cost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/1553309351.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# 1. Plot Cost History\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Memanggil fungsi menggunakan plot.plot_cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Perkembangan Cost (1 - Akurasi) per Iterasi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iterasi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyswarms.utils.plotters' has no attribute 'plot_cost'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"--- MEMULAI OPTIMASI HYPERPARAMETER DENGAN PSO ---\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    optimizer = ps.single.GlobalBestPSO(\n",
    "        n_particles=N_PARTICLES,\n",
    "        dimensions=len(MIN_BOUNDS),\n",
    "        options=PSO_OPTIONS,\n",
    "        bounds=BOUNDS\n",
    "    )\n",
    "\n",
    "    best_cost, best_pos = optimizer.optimize(objective_function, iters=N_ITERATIONS)\n",
    "\n",
    "    # --- Menampilkan Hasil Akhir ---\n",
    "    print(\"\\n\\n\" + \"=\"*50)\n",
    "    print(\"--- OPTIMASI PSO SELESAI ---\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Tampilkan tabel riwayat untuk analisis yang lebih dalam\n",
    "    results_data = []\n",
    "    for i in range(N_ITERATIONS):\n",
    "        for j in range(N_PARTICLES):\n",
    "            lr = optimizer.pos_history[i][j][0]\n",
    "            bs = snap_to_valid_batch_size(optimizer.pos_history[i][j][1])\n",
    "            cost = optimizer.cost_history[i] # Cost history adalah best cost per iterasi\n",
    "        results_data.append({\n",
    "            'iterasi': i + 1,\n",
    "            'best_cost_iterasi_ini': optimizer.cost_history[i],\n",
    "            'best_lr_saat_ini': optimizer.pos_history[i][np.argmin(optimizer.cost_history)][0],\n",
    "            'best_bs_saat_ini': snap_to_valid_batch_size(optimizer.pos_history[i][np.argmin(optimizer.cost_history)][1])\n",
    "        })\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    print(\"\\n--- Ringkasan Hasil per Iterasi ---\")\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "    best_accuracy = 1.0 - best_cost\n",
    "    print(f\"\\nAkurasi validasi tertinggi yang dicapai: {best_accuracy:.4f}\")\n",
    "\n",
    "    print(\"\\n>>> HYPERPARAMETER TERBAIK YANG DITEMUKAN <<<\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"  Learning Rate: {best_pos[0]:.6f}\")\n",
    "    print(f\"  Batch Size: {snap_to_valid_batch_size(best_pos[1])}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "\n",
    "    # --- Visualisasi ---\n",
    "    print(\"\\n--- Visualisasi Proses Optimasi ---\")\n",
    "    \n",
    "    # 1. Plot Cost History\n",
    "    # Memanggil fungsi menggunakan plot.plot_cost\n",
    "    plot.plot_cost(optimizer.cost_history)\n",
    "    plt.title(\"Perkembangan Cost (1 - Akurasi) per Iterasi\", fontsize=14)\n",
    "    plt.xlabel(\"Iterasi\", fontsize=12)\n",
    "    plt.ylabel(\"Best Cost\", fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Plot Contour\n",
    "    try:\n",
    "        plot.plot_contour(pos_history=optimizer.pos_history,\n",
    "                         title=\"Pergerakan Partikel di Ruang Pencarian\",\n",
    "                         designer=None)\n",
    "        plt.xlabel(\"Learning Rate\", fontsize=12)\n",
    "        plt.ylabel(\"Batch Size\", fontsize=12)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nTidak dapat membuat plot kontur: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 87153,
     "sourceId": 200743,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
